{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862dfce0",
   "metadata": {},
   "source": [
    "# $Présentation$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e873939",
   "metadata": {},
   "source": [
    "L'objectif du présent Notebook est d'améliorer les performances obtenus précédament. Pour ce faire on testera dans l'opération de la vectorisation en utilisant 4 nouvelles techniques, i.e. _Unigram Counts_, _Unigram Tf-Idf_, _ Bigram Counts_, _Bigram Tf-Idf_. \n",
    "    \n",
    "Afin de choisir la meilleur technique, pour chaque stratégie, nous divisons le dataset en data de formation et de validation puis nous formons un SGDClassifier et calculons le score. Nous allons par la suite ajuster le modèle obtenu, en cherchant la meilleure combinaison des paramétres suivants (i) _loss_, _learning rate_ et _initial learning rate_, et (ii) _Penalty_ and _Alpha_.\n",
    "    \n",
    "Au final, nous obtenons une précision dans les alentours de 90%. C'est beaucoup mieux que les modeles précédentes et relativement convainquant par rapport à un modèle linéaire simple. Il existe néanmoins des méthodes plus avancées qui donnent de meilleurs résultats. L'état actuel de l'art sur des dataset de ce type est de 97,42% [1, 2].\n",
    "\n",
    "n.b. comme les précédentes, ce notebook requiert l'exécution du notebook *text_Normalisation*, qui désormais se termine par une sauvgarde des reviews après prétraitement (sauvgarde en csv, i.e. encoded_reviews.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c60c7d",
   "metadata": {},
   "source": [
    "# $Initialisation$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e6799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# --\n",
    "\n",
    "import re\n",
    "from os import system, listdir\n",
    "from os.path import isfile, join\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from joblib import dump, load # used for saving and loading sklearn objects\n",
    "from scipy.sparse import save_npz, load_npz # used for saving and loading sparse matrices\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e5e16",
   "metadata": {},
   "source": [
    "### $Reload$ $des$ $données$ $et$ $apperçu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4953634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape : (13630, 5)\n",
      "1    0.862656\n",
      "0    0.137344\n",
      "Name: sentiment, dtype: float64 \n",
      "\n",
      "hongkong tokyo far best look forward biggest orlando enough recommend stay resort enjoy fast track save huge amount stay strategize get fast track pass kiosk nearby ride projection fireworks show\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('encoded_reviews.csv')\n",
    "print('Dataset Shape :', df.shape)\n",
    "df['sentiment'] = df['Rating'] > 2.5\n",
    "df.sentiment = df.sentiment.map({True:1, False:0})\n",
    "print(df.sentiment.value_counts(normalize=True), '\\n')\n",
    "# Let us add a new column\n",
    "#df['text'] = df.Review_Text\n",
    "txt = df.text[0]\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b3619",
   "metadata": {},
   "source": [
    "### $Division$ $entrainement$, $test$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140637e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10904,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts(normalize=True)\n",
    "X = df.text\n",
    "y = df.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0402a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system(\"mkdir 'data_preprocessors'\")\n",
    "system(\"mkdir 'vectorized_data'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f16685",
   "metadata": {},
   "source": [
    "### $Text$ $vectorization$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6d500",
   "metadata": {},
   "source": [
    "On testera dans ce qui suit, l'opération de la vectorisation en utilisant 4 techniques :\n",
    "\n",
    "- Unigram Counts\n",
    "- Unigram Tf-Idf\n",
    "- Bigram Counts\n",
    "- Bigram Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffac40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Unigram Counts\n",
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_vectorizer.fit(X_train.values) \n",
    "dump(unigram_vectorizer, 'data_preprocessors/unigram_vectorizer.joblib')\n",
    "# unigram_vectorizer = load('data_preprocessors/unigram_vectorizer.joblib')\n",
    "\n",
    "X_train_unigram = unigram_vectorizer.transform(X_train.values)\n",
    "save_npz('vectorized_data/X_train_unigram.npz', X_train_unigram)\n",
    "# X_train_unigram = load_npz('vectorized_data/X_train_unigram.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d09088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Unigram Tf-Idf\n",
    "unigram_tf_idf_transformer = TfidfTransformer()\n",
    "unigram_tf_idf_transformer.fit(X_train_unigram)\n",
    "\n",
    "dump(unigram_tf_idf_transformer, 'data_preprocessors/unigram_tf_idf_transformer.joblib')\n",
    "X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)\n",
    "save_npz('vectorized_data/X_train_unigram_tf_idf.npz', X_train_unigram_tf_idf)\n",
    "# X_train_unigram_tf_idf = load_npz('vectorized_data/X_train_unigram_tf_idf.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9257b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Bigram Counts\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "bigram_vectorizer.fit(X_train.values)\n",
    "\n",
    "dump(bigram_vectorizer, 'data_preprocessors/bigram_vectorizer.joblib')\n",
    "X_train_bigram = bigram_vectorizer.transform(X_train.values)\n",
    "\n",
    "save_npz('vectorized_data/X_train_bigram.npz', X_train_bigram)\n",
    "# X_train_bigram = load_npz('vectorized_data/X_train_bigram.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac09e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Bigram Tf-Idf\n",
    "bigram_tf_idf_transformer = TfidfTransformer()\n",
    "bigram_tf_idf_transformer.fit(X_train_bigram)\n",
    "dump(bigram_tf_idf_transformer, 'data_preprocessors/bigram_tf_idf_transformer.joblib')\n",
    "\n",
    "# bigram_tf_idf_transformer = load('data_preprocessors/bigram_tf_idf_transformer.joblib')\n",
    "X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)\n",
    "save_npz('vectorized_data/X_train_bigram_tf_idf.npz', X_train_bigram_tf_idf)\n",
    "# X_train_bigram_tf_idf = load_npz('vectorized_data/X_train_bigram_tf_idf.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd0d20",
   "metadata": {},
   "source": [
    "### $Choix$ $de$ $la$ $meilleure$ $technique$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7436c",
   "metadata": {},
   "source": [
    "Afin de choisir la meilleur technique, pour chaque stratégie, nous divisons le dataset en data de formation et de validation puis nous formons un SGDClassifier et calculons le score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "211a815d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts\n",
      "Train score: 0.99;            Validation score: 0.89\n",
      "\n",
      "Unigram Tf-Idf\n",
      "Train score: 0.97;            Validation score: 0.9\n",
      "\n",
      "Bigram Counts\n",
      "Train score: 1.0;            Validation score: 0.89\n",
      "\n",
      "Bigram Tf-Idf\n",
      "Train score: 1.0;            Validation score: 0.9\n",
      "\n",
      "Duration :  0.84\n"
     ]
    }
   ],
   "source": [
    "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, train_size=0.75, stratify=y\n",
    "    )\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    valid_score = clf.score(X_valid, y_valid)\n",
    "    print(f'{title}\\nTrain score: {round(train_score, 2)};\\\n",
    "            Validation score: {round(valid_score, 2)}\\n')\n",
    "\n",
    "#y_train = df['sentiment'].values # y_train is already calculated\n",
    "start = time.time()\n",
    "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
    "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
    "train_and_show_scores(X_train_bigram, y_train, 'Bigram Counts')\n",
    "train_and_show_scores(X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')\n",
    "end = time.time()\n",
    "print ('Duration : ', round(end-start, 2)) # 1.14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586e301",
   "metadata": {},
   "source": [
    "Dans la quasi-totalité des cas, le meilleur résultat semble être toujours avec du Bigram avec tf-idf (précision de validation : 0.9)\n",
    "\n",
    "Nous l'utiliserons par la suite pour le réglage des hyper-paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d0374",
   "metadata": {},
   "source": [
    "### $Hyperparameter$ $tuning$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37110fe",
   "metadata": {},
   "source": [
    "$Phase$ $1:$  On cherche la meilleure combinaison : loss, learning rate et initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "064f2a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'eta0': 0.007047183870982173, 'learning_rate': 'optimal', 'loss': 'squared_hinge'}\n",
      "Best score: 0.9034302924758864\n",
      "Duration :  141.22 s\n"
     ]
    }
   ],
   "source": [
    "#X_train = X_train_bigram \n",
    "X_train = X_train_bigram_tf_idf\n",
    "#X_train = X_train_unigram_tf_idf\n",
    "\n",
    "\n",
    "# Phase 1: loss, learning rate and initial learning rate\n",
    "clf = SGDClassifier()\n",
    "\n",
    "distributions = dict(\n",
    "    loss=['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    learning_rate=['optimal', 'invscaling', 'adaptive'],\n",
    "    eta0=uniform(loc=1e-7, scale=1e-2)\n",
    ")\n",
    "\n",
    "random_search_cv = RandomizedSearchCV(\n",
    "    estimator=clf,\n",
    "    param_distributions=distributions,\n",
    "    cv=5,\n",
    "    n_iter=50\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "random_search_cv.fit(X_train, y_train)\n",
    "print(f'Best params: {random_search_cv.best_params_}')\n",
    "print(f'Best score: {random_search_cv.best_score_}') #0.90\n",
    "\n",
    "end = time.time()\n",
    "print ('Duration : ', round(end-start, 2), 's') # 305.89s 69s  165s 141.22s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a4c428",
   "metadata": {},
   "source": [
    "$Phase$ $2:$  Penalty and Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877f3e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 1.1817931458286057e-05, 'penalty': 'elasticnet'}\n",
      "Best score: 0.9074653492001395\n",
      "Duration :  83.64 s\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: penalty and alpha\n",
    "clf = SGDClassifier()\n",
    "\n",
    "distributions = dict(\n",
    "    penalty=['l1', 'l2', 'elasticnet'],\n",
    "    alpha=uniform(loc=1e-6, scale=1e-4)\n",
    ")\n",
    "\n",
    "random_search_cv = RandomizedSearchCV(\n",
    "    estimator=clf,\n",
    "    param_distributions=distributions,\n",
    "    cv=5,\n",
    "    n_iter=50\n",
    ")\n",
    "start = time.time()\n",
    "random_search_cv.fit(X_train, y_train)\n",
    "print(f'Best params: {random_search_cv.best_params_}') # {'alpha': 2.6334034050575763e-05, 'penalty': 'l2'}\n",
    "print(f'Best score: {random_search_cv.best_score_}') # 0.91 0.90 0.9\n",
    "end = time.time()\n",
    "print ('Duration : ', round(end-start, 2), 's') # 221 38.47s 97.18s 83.64s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e2bce",
   "metadata": {},
   "source": [
    "### $Sauvgardons$ $le$ $meilleur$ $classifier$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4bbbcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifiers/sgd_classifier.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system(\"mkdir 'classifiers'\")\n",
    "sgd_classifier = random_search_cv.best_estimator_\n",
    "dump(random_search_cv.best_estimator_, 'classifiers/sgd_classifier.joblib')\n",
    "# sgd_classifier = load('classifiers/sgd_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "206c78db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "sgd_classifier = load('classifiers/sgd_classifier.joblib')\n",
    "\n",
    "X_test = bigram_vectorizer.transform(X_test.values)\n",
    "X_test = bigram_tf_idf_transformer.transform(X_test)\n",
    "\n",
    "score = sgd_classifier.score(X_test, y_test)\n",
    "print(round(score, 2)) #0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22988948",
   "metadata": {},
   "source": [
    "### $Testons$ $à$ $nouveau$ $notre$ $model$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c899cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       381\n",
      "           1       0.94      0.95      0.95      2345\n",
      "\n",
      "    accuracy                           0.91      2726\n",
      "   macro avg       0.81      0.79      0.80      2726\n",
      "weighted avg       0.90      0.91      0.90      2726\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>2234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite    0     1\n",
       "Classe réelle            \n",
       "0               236   145\n",
       "1               111  2234"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#help(classification_report)\n",
    "sgd_classifier = load('classifiers/sgd_classifier.joblib')\n",
    "type (sgd_classifier)\n",
    "sgd_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_classifier.predict(X_test)\n",
    "print('Classification Report : \\n\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "# Calcul et affichage de la matrice de confusion\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a05bd",
   "metadata": {},
   "source": [
    "Au final, nous obtenons une précision au alentours de 90%. C'est beaucoup mieux que les modeles précédentes et relativement convainquant par rapport à un modèle linéaire simple. \n",
    "\n",
    "Il existe néanmoins des méthodes plus avancées qui donnent de meilleurs résultats. L'état actuel de l'art sur des dataset de ce type est de 97,42% [1, 2]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bca593",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d5642",
   "metadata": {},
   "source": [
    "- **[1]  :** https://towardsdatascience.com/building-a-sentiment-classifier-using-scikit-learn-54c8e7c5d2f0\n",
    "- **[2]  :** https://www.aclweb.org/anthology/P19-2057.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
