{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371693ed",
   "metadata": {},
   "source": [
    "# Présentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390332b7",
   "metadata": {},
   "source": [
    "Dans ce Notebook, nous testons différents algo de ML, e.g. : _Gradient Boosting_, _Logistic Regression_, _Multinomial NB_, _Random Forest_. Nous allons les évaluer et voir que, dans les meilleurs des cas, les performances ne dépasseraient pas les 82%. \n",
    "\n",
    "Plus de techniques (notament de véctorisation) vont être utilisées au cours du notebook suivants (predictions_02) et qui vont améliorer significativement les performances obtenus.\n",
    "\n",
    "\n",
    "n.b. ce notebook requiert l'exécution du notebook *text_Normalisation*, qui  se termine par une sauvgarde des reviews après prétraitement (sauvgarde en csv, i.e. encoded_reviews.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4cf05c",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf872feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e77b2",
   "metadata": {},
   "source": [
    "## $Extraction$ $des$ $données$ $et$ $apperçu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e18689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape : (13630, 5)\n",
      "Dataset overview :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-3</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>1</td>\n",
       "      <td>hongkong tokyo far best look forward biggest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-6</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>go april easter weekend say june choose date l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>fantastic queue decent best apparently manage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>realise school holiday go consequently extreme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>missing</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>make warm fuzzy actual big make fun fill happy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating Year_Month     Reviewer_Location  sentiment  \\\n",
       "0       5     2019-3  United Arab Emirates          1   \n",
       "1       4     2018-6        United Kingdom          1   \n",
       "2       5     2019-4        United Kingdom          1   \n",
       "3       4     2019-4             Australia          1   \n",
       "4       5    missing                France          1   \n",
       "\n",
       "                                                text  \n",
       "0  hongkong tokyo far best look forward biggest o...  \n",
       "1  go april easter weekend say june choose date l...  \n",
       "2  fantastic queue decent best apparently manage ...  \n",
       "3  realise school holiday go consequently extreme...  \n",
       "4  make warm fuzzy actual big make fun fill happy...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('encoded_reviews.csv')\n",
    "print('Dataset Shape :', df.shape)\n",
    "print('Dataset overview :\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1e103",
   "metadata": {},
   "source": [
    "### $Division$ $entrainement$, $test$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f979a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10904,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts(normalize=True)\n",
    "X = df.text\n",
    "y = df.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffce64d",
   "metadata": {},
   "source": [
    "### $Preprocessing$ $(Text$ $vectorization)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0170f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train).todense()\n",
    "X_test = vectorizer.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eee97f",
   "metadata": {},
   "source": [
    "Dans ce qui suit, nous testons différents algo de ML suivants :\n",
    "\n",
    "- Gradient Boosting\n",
    "- Logistic Regression\n",
    "- Multinomial NB\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cfec18",
   "metadata": {},
   "source": [
    "### $Gradient$ $Boosting$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44e2a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation done in  1114.24 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = GradientBoostingClassifier(n_estimators = 100, learning_rate = 1.0, max_depth = 1, random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "end = time.time()\n",
    "print('Calculation done in ', round(end - start, 2), 's') # ==> 109s 1190s 1112.37s 1209.06s 1114.24s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad762a17",
   "metadata": {},
   "source": [
    "##### $ Evaluation $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "200cf253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.48       381\n",
      "           1       0.91      0.95      0.93      2345\n",
      "\n",
      "    accuracy                           0.88      2726\n",
      "   macro avg       0.75      0.68      0.71      2726\n",
      "weighted avg       0.86      0.88      0.87      2726\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite    0     1\n",
       "Classe réelle            \n",
       "0               154   227\n",
       "1               106  2239"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#help(classification_report)\n",
    "print('Classification Report : \\n\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "# Calcul et affichage de la matrice de confusion\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338bf4a",
   "metadata": {},
   "source": [
    "### $ Essayons$ $d'autre$ $méthodes$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687f7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083154a",
   "metadata": {},
   "source": [
    "### $Logistic$ $Regression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb15314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelbasset/anaconda2/envs/yandex/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.990\n",
      "Test set score: 0.893\n",
      "Calculation done in  168.79 s\n",
      "Classification Report : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58       381\n",
      "           1       0.93      0.95      0.94      2345\n",
      "\n",
      "    accuracy                           0.89      2726\n",
      "   macro avg       0.78      0.74      0.76      2726\n",
      "weighted avg       0.89      0.89      0.89      2726\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite    0     1\n",
       "Classe réelle            \n",
       "0               201   180\n",
       "1               113  2232"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "end = time.time()\n",
    "print('Calculation done in ', round(end - start, 2), 's') # ==> 395s/383.6/168s\n",
    "\n",
    "#help(classification_report)\n",
    "print('Classification Report : \\n\\n', classification_report(y_test, pred_logreg))\n",
    "\n",
    "# Calcul et affichage de la matrice de confusion\n",
    "confusion_matrix = pd.crosstab(y_test, pred_logreg, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3e445",
   "metadata": {},
   "source": [
    "### $Multinomial$ $NB$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799fbda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.934\n",
      "Test set score: 0.898\n",
      "Calculation done in  145.5 s\n",
      "Classification Report : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61       381\n",
      "           1       0.93      0.95      0.94      2345\n",
      "\n",
      "    accuracy                           0.90      2726\n",
      "   macro avg       0.79      0.76      0.77      2726\n",
      "weighted avg       0.89      0.90      0.89      2726\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>2235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite    0     1\n",
       "Classe réelle            \n",
       "0               213   168\n",
       "1               110  2235"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(nb.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(nb.score(X_test, y_test)))\n",
    "pred_nb = nb.predict(X_test)\n",
    "end = time.time()\n",
    "print('Calculation done in ', round(end - start, 2), 's') # ==> 125.26s, 85.01s, 145.5s\n",
    "\n",
    "print('Classification Report : \\n\\n', classification_report(y_test, pred_nb))\n",
    "# Calcul et affichage de la matrice de confusion\n",
    "confusion_matrix = pd.crosstab(y_test, pred_nb, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef9e09",
   "metadata": {},
   "source": [
    "### $Simple$ $Random$ $Forest$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88062dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.862\n",
      "Calculation done in  253.66 s\n",
      "Classification Report : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.02      0.04       381\n",
      "           1       0.86      1.00      0.93      2345\n",
      "\n",
      "    accuracy                           0.86      2726\n",
      "   macro avg       0.83      0.51      0.48      2726\n",
      "weighted avg       0.85      0.86      0.80      2726\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite  0     1\n",
       "Classe réelle          \n",
       "0               8   373\n",
       "1               2  2343"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(rf.score(X_test, y_test)))\n",
    "pred_rf = rf.predict(X_test)\n",
    "end = time.time()\n",
    "print('Calculation done in ', round(end - start, 2), 's') # ==> 233.01s, 180.49s\n",
    "\n",
    "print('Classification Report : \\n\\n', classification_report(y_test, pred_rf))\n",
    "# Calcul et affichage de la matrice de confusion\n",
    "confusion_matrix = pd.crosstab(y_test, pred_rf, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8aef85",
   "metadata": {},
   "source": [
    "# Discusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51da9bd",
   "metadata": {},
   "source": [
    "Il est clair que malgré la vectorisation du texte et les différents opérations de nettoiyage (80%-82%), les résultats laissent toujours à désirer. Dans le notebook suivant, on va essayer d'utiliser d'autres approches (_en plus du \"Bag of Words\"_) avec quelques astuces qui nous permettent de gagner bouceaup en temps et en performence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda299f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
